{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize Expresso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "ds = load_from_disk(\"/home/shaan/Projects/Dataset/datasets/encoded_custom_data\")\n",
    "ds = ds.with_format('torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to drop everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#supported_styles = [\"confused\", \"enunciated\", \"happy\", \"laughing\", \"default\", \"sad\", \"whisper\", \"emphasis\"]\n",
    "#ds = ds.filter(lambda r: r[\"style\"] in supported_styles, num_proc=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add control tokens to model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../inits/csm-1b-expresso/tokenizer_config.json',\n",
       " '../inits/csm-1b-expresso/special_tokens_map.json',\n",
       " '../inits/csm-1b-expresso/tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "init_folder = \"../inits/csm-1b-expresso\"\n",
    "os.makedirs(init_folder, exist_ok=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"unsloth/Llama-3.2-1B\")\n",
    "\n",
    "tokenizer.save_pretrained(init_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Add parent directory to path to find modeling module\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize to CSM format\n",
    "\n",
    "Now let's load our new tokenizer back again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling.utils import PromptEncoder\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(init_folder)\n",
    "prompt_encoder = PromptEncoder(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we prepare the inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging # Optional: for warnings\n",
    "\n",
    "# Assuming prompt_encoder is correctly defined with the base tokenizer\n",
    "\n",
    "def tokenize_row(row: dict):\n",
    "    # --- Text Input: NO Style Token ---\n",
    "    text_input = row.get(\"text\", \"\") # Get text, default to empty if missing\n",
    "\n",
    "    # --- Speaker ID Handling: Correct for Custom Data ---\n",
    "    try:\n",
    "        # Assumes 'speaker_id' column has strings like \"0\", \"1\", ...\n",
    "        speaker_id_int = int(row[\"speaker_id\"])\n",
    "    except (ValueError, KeyError) as e:\n",
    "        logging.warning(f\"Could not parse speaker_id '{row.get('speaker_id', 'N/A')}' as int. Using 0. Error: {e}\")\n",
    "        speaker_id_int = 0 # Use a default speaker ID if parsing fails\n",
    "\n",
    "    # --- Checks and Tokenization ---\n",
    "    if 'codes' not in row:\n",
    "         logging.warning(f\"Warning: Missing 'codes' in row. Skipping.\")\n",
    "         return {\"ground_truth\": torch.empty(0, 33), \"ground_truth_masks\": torch.empty(0, 33)}\n",
    "    codes_tensor = row['codes']\n",
    "    if not isinstance(codes_tensor, torch.Tensor):\n",
    "         logging.warning(f\"Warning: 'codes' is not a tensor (type: {type(codes_tensor)}). Skipping.\")\n",
    "         return {\"ground_truth\": torch.empty(0, 33), \"ground_truth_masks\": torch.empty(0, 33)}\n",
    "\n",
    "    # Call the tokenizer with corrected inputs (no style token)\n",
    "    text_tokens, text_masks = prompt_encoder._tokenize_text_segment(\n",
    "        text_input, speaker_id_int\n",
    "    )\n",
    "    audio_tokens, audio_masks = prompt_encoder._tokenize_audio(codes_tensor)\n",
    "\n",
    "    if text_tokens.numel() == 0 or audio_tokens.numel() == 0:\n",
    "         logging.warning(f\"Warning: Empty tokens generated for row text: '{text_input}'\")\n",
    "         return {\"ground_truth\": torch.empty(0, 33), \"ground_truth_masks\": torch.empty(0, 33)}\n",
    "\n",
    "    return {\n",
    "        \"ground_truth\": torch.cat([text_tokens, audio_tokens], dim=0),\n",
    "        \"ground_truth_masks\": torch.cat([text_masks, audio_masks], dim=0),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 14584/14584 [00:02<00:00, 6056.60 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tokenized custom data (no style) to: ../datasets/tokenized_custom_data_no_style\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "import logging # Optional for filtering log\n",
    "\n",
    "# Assuming 'ds' holds the loaded encoded_custom_data dataset\n",
    "# Assuming 'tokenize_row' is the correct version (no style, correct speaker ID)\n",
    "\n",
    "orig_colnames = ds.column_names\n",
    "ds_mapped = ds.map(tokenize_row, num_proc=12, remove_columns=orig_colnames) # Assign to new var\n",
    "\n",
    "# --- Optional but Recommended: Filter out failed tokenizations ---\n",
    "initial_count = len(ds_mapped)\n",
    "ds_filtered = ds_mapped.filter(lambda x: x['ground_truth'].numel() > 0)\n",
    "filtered_count = len(ds_filtered)\n",
    "if initial_count != filtered_count:\n",
    "    logging.warning(f\"Filtered out {initial_count - filtered_count} examples due to tokenization errors.\")\n",
    "# --- End Optional Filter ---\n",
    "\n",
    "\n",
    "# Structure as DatasetDict (using the filtered dataset if you added that step)\n",
    "ds_final = DatasetDict({\n",
    "    \"train\": ds_filtered # Use ds_filtered if you added the filter step, otherwise use ds_mapped\n",
    "})\n",
    "\n",
    "# --- CORRECTED Save Path ---\n",
    "output_path = \"../datasets/tokenized_custom_data_no_style\" # Use a descriptive name\n",
    "ds_final.save_to_disk(output_path)\n",
    "print(f\"Saved tokenized custom data (no style) to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
